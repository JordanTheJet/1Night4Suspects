# LLM Interrogation System - WebGAL Integration

## Overview

This integration adds **AI-powered interrogation mode** to the WebGAL detective game. Players receive context-aware "Smart Suggestions" - strategic question buttons generated by Claude Haiku 4.5 that evolve based on the conversation.

## What's New

### Features
- **Dynamic Interrogation Mode**: Harper responds naturally using Claude AI
- **Smart Suggestions**: 3-4 AI-generated strategic questions after each response
- **Custom Questions**: Players can type their own questions anytime
- **Visual Feedback**: Real-time stress/trust bars and emotional state indicators
- **Cost-Efficient**: ~$0.0004 per turn using Claude Haiku 4.5

## Files Created/Modified

### New Files

**Game Script Components:**
```
src/Core/gameScripts/llmInterrogate/
├── index.tsx                    # Main React component
└── llmInterrogate.module.scss   # Styling
```

**Scene Files:**
```
public/game/scene/
└── harper_llm_demo.txt          # AI interrogation entry point
```

**Configuration:**
```
.env.example                     # API key template
```

### Modified Files

**Core Integration:**
- `src/Core/controller/scene/sceneInterface.ts` - Added `llmInterrogate` command type
- `src/Core/parser/sceneParser.ts` - Registered command handler
- `packages/parser/src/interface/sceneInterface.ts` - Updated parser enum
- `public/game/scene/start.txt` - Added AI mode option

**Controller Fix:**
- `src/Core/controller/llm/interrogationController.ts` - Fixed presentEvidence return type

## Setup Instructions

### 1. Configure API Key

Create a `.env` file in `/packages/webgal/`:

```bash
cd /packages/webgal
cp .env.example .env
```

Edit `.env` and add your Anthropic API key:
```
VITE_ANTHROPIC_API_KEY=sk-ant-api03-...
```

Get your API key from: https://console.anthropic.com/

### 2. Build the Project

```bash
# From the root WebGAL directory
npm run build
```

### 3. Run Development Server

```bash
npm run dev
```

### 4. Access the Game

Open your browser to the dev server URL (typically `http://localhost:5173`)

## How to Use

### For Players

1. **Start the Game** - Launch WebGAL
2. **Select AI Mode** - Choose "Harper Lin (AI Mode)" from the interrogation menu
3. **Read Introduction** - Learn about AI interrogation features
4. **Interrogate** - Click suggested questions or type your own
5. **Watch Stats** - Monitor stress/trust levels
6. **End Session** - Click "End Interrogation" when done

### For Developers

#### Adding LLM Interrogation to a Scene

**Basic Usage:**
```
llmInterrogate:Harper Lin;
```

**Full Example Scene:**
```
; Set background
changeBg:interrogation_room.png -next;

; Introduction dialogue
This is an AI-powered interrogation.;
Harper will respond dynamically to your questions.;

; Launch LLM mode
llmInterrogate:Harper Lin;

; After interrogation ends
You've completed the interrogation.;
choose:Review evidence:evidence.txt|Continue:next_scene.txt;
```

#### Custom Suspect Configuration

To interrogate different suspects, modify:
```
src/Core/controller/llm/harperPrompt.ts
src/Core/controller/llm/interrogationState.ts
```

## Architecture

### Component Flow

```
WebGAL Scene File (harper_llm_demo.txt)
    ↓
llmInterrogate Command
    ↓
LLMInterrogation Component (React)
    ↓
InterrogationController
    ↓
ClaudeClient (Anthropic API)
    ↓
Returns: { response, suggestions, emotionalState, stats }
    ↓
UI Updates (response + suggestion buttons)
```

### Key Components

**1. LLM Integration Layer** (`src/Core/controller/llm/`)
- `claudeClient.ts` - Anthropic API wrapper
- `interrogationController.ts` - Main controller
- `interrogationState.ts` - State management
- `harperPrompt.ts` - System prompt

**2. WebGAL Command** (`src/Core/gameScripts/llmInterrogate/`)
- `index.tsx` - React component with UI
- Renders in `chooseContainer` div
- Blocks game progression until ended

**3. Parser Integration**
- Registered as `commandType.llmInterrogate`
- Handled like `choose` and `getUserInput`

## UI Components

### Main Interface
- **Header**: Suspect name + real-time stats (stress/trust bars)
- **Response Box**: Harper's answer with emotional state badge
- **Suggestions**: 3-4 clickable question buttons
- **Custom Input**: Collapsible text input for custom questions
- **Actions**: End interrogation button

### Emotional States
- `calm` - Green badge
- `nervous` - Yellow/orange badge
- `defensive` - Orange badge
- `angry` - Red badge
- `breaking` - Purple badge

### Stats Bars
- **Stress**: Red gradient (0-100%)
- **Trust**: Blue gradient (0-100%)

## API Usage

### Cost Estimates
- **Per Turn**: ~$0.0004 USD
- **10-minute session**: ~$0.01 USD
- **Model**: Claude Haiku 4.5 (fast & cheap)

### Rate Limits
- Default Anthropic limits apply
- Consider implementing caching for repeated questions
- No rate limiting implemented in code

## Error Handling

### Graceful Degradation
- API key missing → Shows error message with return button
- API call fails → Displays error with retry option
- Network timeout → Error message displayed
- Invalid response → Falls back to generic suggestions

### Debug Mode
Check browser console for:
```
✅ Interrogation Controller initialized
✅ API call successful
❌ Error in askHarper: [details]
```

## Customization

### Styling
Modify `llmInterrogate.module.scss` to customize:
- Colors and themes
- Button styles
- Stat bar appearance
- Animations and transitions

### Prompts
Edit `harperPrompt.ts` to:
- Change suspect personality
- Add new evidence types
- Modify emotional state logic
- Adjust suggestion generation

### Stats
Configure in `interrogationState.ts`:
- Initial values
- Stat change rules
- Evidence impact
- Threshold triggers

## Testing

### Manual Testing
1. Test with API key set
2. Test without API key (should show error)
3. Test custom questions
4. Test suggestion clicks
5. Verify stats update correctly
6. Check end interrogation flow

### Automated Tests
```bash
# Test LLM integration
npm run test:llm  # If test script exists

# Or run individual test
node src/Core/controller/llm/test.ts
```

## Troubleshooting

### "API Key not configured"
- Ensure `.env` file exists in `/packages/webgal/`
- Verify `VITE_ANTHROPIC_API_KEY` is set
- Restart dev server after adding `.env`

### Suggestions not appearing
- Check console for API errors
- Verify Claude response format
- Check `parseStructuredResponse()` logic

### Build errors
- Rebuild parser package: `cd packages/parser && npm run build`
- Clear cache: `rm -rf node_modules/.vite`
- Reinstall: `npm install`

### Stats not updating
- Check `parseStatChanges()` in interrogationState.ts
- Verify stat markers in Claude responses: `[+stress:10]`

## Future Enhancements

### Potential Features
- [ ] Evidence presentation UI
- [ ] Conversation transcript export
- [ ] Streaming responses (typing effect)
- [ ] Multi-suspect interrogation
- [ ] Save/load interrogation state
- [ ] Analytics dashboard
- [ ] Voice synthesis for responses
- [ ] Comparison mode (Static vs AI side-by-side)

### Performance Optimizations
- [ ] Response caching
- [ ] Debounce custom input
- [ ] Lazy load LLM controller
- [ ] Preload initial response

## Technical Notes

### React Integration
- Uses ReactDOM.render (legacy) to match WebGAL pattern
- Renders in `chooseContainer` div (same as choose command)
- Redux Provider wraps component for store access

### State Management
- Uses WebGAL store for font preferences
- LLM state managed separately via singleton controller
- No persistence between interrogations (resets on new session)

### Performance
- Single LLM controller instance (singleton)
- Conversation history maintained for context
- ~1-2 second response time with Claude Haiku

## Credits

**LLM Integration**: Claude Haiku 4.5 (Anthropic)
**WebGAL Engine**: https://github.com/MakinoharaShoko/WebGAL
**Game Design**: Detective interrogation mechanics

## License

Follows WebGAL project license. LLM integration code is provided as-is for hackathon demo purposes.

---

## Quick Start Summary

```bash
# 1. Setup
cp .env.example .env
# Add your ANTHROPIC_API_KEY

# 2. Build
npm run build

# 3. Run
npm run dev

# 4. Play
# Select "Harper Lin (AI Mode)" in game
```

**Integration Complete!** The AI detective partner is ready to help players conduct dynamic interrogations.
